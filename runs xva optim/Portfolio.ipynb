{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_SIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_dict_print(a_dict, level=1):\n",
    "    keys = a_dict.keys()\n",
    "    keys.sort()\n",
    "    for k in keys:\n",
    "        if type(a_dict[k]) is dict:\n",
    "            print \"\".join([\"-\" for i in range(level)]) + k\n",
    "            rec_dict_print(a_dict[k], level + 2)\n",
    "        else:\n",
    "            print \"\".join([\"-\" for i in range(level)]) + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dill\n",
    "\n",
    "loaded_data = None\n",
    "\n",
    "with open('precomputed_sims/data%i.pkl' % (NB_SIM), 'rb') as f:\n",
    "    loaded_data = dill.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-N\n",
      "-credit\n",
      "---bc_ids\n",
      "---bc_subsets_indexes\n",
      "---copula\n",
      "---default_times\n",
      "-randomization\n",
      "---distrib\n",
      "-----loc\n",
      "-----scale\n",
      "---maturity\n",
      "---zetas\n",
      "-underlyings\n"
     ]
    }
   ],
   "source": [
    "rec_dict_print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = loaded_data[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maturity = 5.0 years\n"
     ]
    }
   ],
   "source": [
    "# Instead of taking 365 standard days or 252 trading days\n",
    "# in order to get some easy computations for the eqty and df time grids\n",
    "# I chose to take 360 days of tradings\n",
    "\n",
    "step = 1 / 360.\n",
    "delta = 5 * step\n",
    "\n",
    "maturity = loaded_data[\"randomization\"][\"maturity\"]\n",
    "\n",
    "print \"Maturity = %s years\" % maturity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from finance.discountfactor import ConstantRateDiscountFactor \n",
    "\n",
    "r = 0.02\n",
    "discount = ConstantRateDiscountFactor(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of paths: 20000\n",
      "kappa = 0.12, sigma = 0.2\n"
     ]
    }
   ],
   "source": [
    "udlyings = loaded_data[\"underlyings\"]\n",
    "\n",
    "print \"Maximum number of paths: %i\" % len(udlyings)\n",
    "\n",
    "gbm0 = udlyings[0]\n",
    "\n",
    "kappa = gbm0.drifts[0][0]\n",
    "sigma = gbm0.vols[0][0]\n",
    "print \"kappa = %s, sigma = %s\" % (kappa, sigma)\n",
    "\n",
    "time_grid = gbm0.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derivatives_nb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swap contract of maturity T = 5 years, over S^0 with strike K = 134.306, paying at {0.00, 0.25, 0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75, 4.00, 4.25, 4.50, 4.75, 5.00}\n",
      "\n",
      "Price swap at t=0 without 1st coupon = 0.0\n"
     ]
    }
   ],
   "source": [
    "from finance.products.european.swap import (\n",
    "    SwapContract,\n",
    ")\n",
    "\n",
    "swap_delta = 0.25\n",
    "\n",
    "swap_dates = SwapContract.generate_payment_dates(0, maturity, swap_delta)\n",
    "swap = SwapContract(gbm0, discount, swap_dates)\n",
    "\n",
    "price_0 = swap.price(0., incl_next_coupon=True)\n",
    "\n",
    "print swap\n",
    "print \"\\nPrice swap at t=0 without 1st coupon = %s\" % price_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notional on the swap: 0.0015687485053\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "p_fixed = 1.\n",
    "strike = swap.strike\n",
    "\n",
    "delta_times = swap.delta_time\n",
    "discount_factors = [discount(t) for t in swap.pillars[1:]]\n",
    "\n",
    "delta_beta_sum = np.dot(delta_times, discount_factors)\n",
    "\n",
    "notional = p_fixed / (strike*delta_beta_sum)\n",
    "\n",
    "print \"Notional on the swap: %s\" % notional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obligor numbers: 125\n",
      "Counterparties id: [17, 9, 29, 26, 50, 4, 5, 13, 64] (nb = 9)\n"
     ]
    }
   ],
   "source": [
    "copula = loaded_data[\"credit\"][\"copula\"]\n",
    "\n",
    "c_subsets_indexes = loaded_data[\"credit\"][\"bc_subsets_indexes\"]\n",
    "\n",
    "obligors_nb = len(copula.subsets[c_subsets_indexes[-1]][0])\n",
    "print \"Obligor numbers: %s\" % obligors_nb\n",
    "\n",
    "c_ids = [17, 9, 29, 26, 50, 4, 5, 13, 64]\n",
    "c_positions = [0.69, -0.46, -0.44, -0.36, 0.34, 0.23, 0.09, -0.05, -0.04]\n",
    "\n",
    "print \"Counterparties id: %s (nb = %s)\" % (c_ids, len(c_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.    0.    0.    0.    4.6   1.8   0.    0.    0.   -9.2   0.    0.\n",
      "   0.   -1.    0.    0.    0.   13.8   0.    0.    0.    0.    0.    0.\n",
      "   0.    0.   -7.2   0.    0.   -8.8   0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.8   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.   -0.8   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "positions = np.zeros(obligors_nb)\n",
    "for idx, ps in zip(c_ids, c_positions):\n",
    "    positions[idx] = ps\n",
    "\n",
    "positions = positions / -positions[13]\n",
    "positions = np.array(positions).reshape(positions.size, 1)\n",
    "\n",
    "print positions.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_times_mat = loaded_data[\"credit\"][\"default_times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_default_times_sim(c_ids, N, default_times_mat, copula, subsets_indexes):\n",
    "    matrix_def = np.zeros((len(c_ids), N))\n",
    "    c = np.array(c_ids)\n",
    "    \n",
    "    for j, c_id in enumerate(c_ids):\n",
    "        cp_subsets_indexes = copula.get_indexes_including(c_id)\n",
    "        c_df_times_indexes = [ii for ii, ind in enumerate(subsets_indexes) if ind in cp_subsets_indexes]\n",
    "        \n",
    "        c_df_times_mat = default_times_mat[:, c_df_times_indexes]\n",
    "        c_df_times = c_df_times_mat.min(axis=1)\n",
    "        \n",
    "        matrix_def[j] = c_df_times\n",
    "        \n",
    "    matrix_def[matrix_def==1000.] = np.nan\n",
    "        \n",
    "    df_default_times = pd.DataFrame(matrix_def, index=c)\n",
    "    return df_default_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19990</th>\n",
       "      <th>19991</th>\n",
       "      <th>19992</th>\n",
       "      <th>19993</th>\n",
       "      <th>19994</th>\n",
       "      <th>19995</th>\n",
       "      <th>19996</th>\n",
       "      <th>19997</th>\n",
       "      <th>19998</th>\n",
       "      <th>19999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.697222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.352778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.155556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.472222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.155556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.886111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.847222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.091667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.319444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.658333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.913889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.155556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.358333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1      2      3      4         5         6         7      \\\n",
       "17  4.697222       NaN    NaN    NaN    NaN       NaN  3.352778       NaN   \n",
       "9        NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "29  0.680556       NaN    NaN    NaN    NaN  3.400000  4.472222       NaN   \n",
       "26       NaN  1.847222    NaN    NaN    NaN       NaN       NaN  2.375000   \n",
       "50       NaN       NaN    NaN    NaN    NaN       NaN       NaN  3.658333   \n",
       "4        NaN       NaN    NaN    NaN    NaN  2.938889       NaN       NaN   \n",
       "5        NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "13       NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "64       NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "\n",
       "       8         9        ...     19990  19991  19992     19993  19994  \\\n",
       "17  3.155556       NaN    ...       NaN    NaN    NaN  0.722222    NaN   \n",
       "9        NaN       NaN    ...       NaN    NaN    NaN       NaN    NaN   \n",
       "29  3.155556       NaN    ...       NaN    NaN    NaN  0.722222    NaN   \n",
       "26  1.100000  2.091667    ...       NaN    NaN    NaN  0.722222    NaN   \n",
       "50       NaN       NaN    ...       NaN    NaN    NaN       NaN    NaN   \n",
       "4        NaN       NaN    ...       NaN    0.6    NaN       NaN    NaN   \n",
       "5        NaN       NaN    ...       NaN    NaN    NaN       NaN    NaN   \n",
       "13       NaN       NaN    ...       NaN    NaN    NaN       NaN    NaN   \n",
       "64  3.155556       NaN    ...       NaN    NaN    NaN  0.722222    NaN   \n",
       "\n",
       "       19995  19996     19997     19998     19999  \n",
       "17       NaN    NaN       NaN       NaN       NaN  \n",
       "9        NaN    NaN       NaN       NaN       NaN  \n",
       "29  2.886111    NaN       NaN       NaN       NaN  \n",
       "26       NaN    NaN  1.319444       NaN       NaN  \n",
       "50       NaN    NaN       NaN       NaN       NaN  \n",
       "4        NaN    NaN       NaN       NaN  1.913889  \n",
       "5        NaN    NaN       NaN       NaN       NaN  \n",
       "13       NaN    NaN       NaN       NaN       NaN  \n",
       "64       NaN    NaN       NaN  2.358333       NaN  \n",
       "\n",
       "[9 rows x 20000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_times = get_default_times_sim(c_ids, N, default_times_mat, copula, c_subsets_indexes)\n",
    "default_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio P&L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for:\n",
    "\n",
    "\\begin{equation*}\n",
    "% \\sum_{t < \\tau_i^{\\delta} \\leq t+1} \n",
    "\\left( \n",
    "\\beta_{\\tau_i^{\\delta}} \\left( MtM_{\\tau_i^\\delta}^i + \\Delta^i_{\\tau_i^\\delta} \\right)\n",
    "-\\beta_{\\tau_i} \\left( {\\rm VM}_{\\tau_i}^i + {\\rm IM}_{\\tau_i}^i \\right)\n",
    "\\right)^+ \\, \\forall i\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import time_offseter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  9, 29, 26, 50,  4,  5, 13, 64], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_cva = np.arange(0, maturity, 0.5)\n",
    "\n",
    "shifted_times_cva = times_cva + 1.\n",
    "shifted_times_cva[-1] = maturity\n",
    "\n",
    "default_times.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def fact_(swap_, discount_, kappa_, delta_, t_):\n",
    "    time_grid_ = swap_.underlying.time\n",
    "    t_delta = time_offseter(t_ + delta_, time_grid_, True)\n",
    "    \n",
    "    coupon_dates_ = swap_.pillars\n",
    "    l_t_delta_ = np.searchsorted(coupon_dates_, t_delta, side='left')\n",
    "\n",
    "    beta_T_l_ = map(discount_, coupon_dates_[l_t_delta_ + 1 :])    \n",
    "    h_l_ = swap_.delta_time[l_t_delta_ : ]\n",
    "    \n",
    "    T_l_m1_ = kappa_ * coupon_dates_[l_t_delta_ : -1]\n",
    "    exp_factor_ = map(np.exp, T_l_m1_)\n",
    "    \n",
    "    tmp_ = np.multiply(exp_factor_, h_l_)    \n",
    "    res = np.dot(beta_T_l_, tmp_)\n",
    "    \n",
    "    return res\n",
    "\n",
    "fact = partial(fact_, swap, discount, kappa, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_1y_ahead_loss_(fact_f_, kappa_, delta_, notional_, positions_, times_cva_, shifted_times_cva_, default_times_, udls_):\n",
    "    ccp_loss_1y_ = dict()\n",
    "    \n",
    "    N_ = len(udls_)\n",
    "    \n",
    "    c_ids_ = default_times_.index.values\n",
    "    \n",
    "    for t0_, t1_ in zip(times_cva_, shifted_times_cva_):\n",
    "        key = \"[%.2f, %.2f]\" % (t0_, t1_)\n",
    "        print key\n",
    "        ccp_loss_1y_[key] = pd.DataFrame(0., index=range(N_), columns=c_ids_)\n",
    "        \n",
    "        for j_ in xrange(N_):\n",
    "            udl_ = udls_[j_]\n",
    "            time_grid_ = udl_.time\n",
    "            tau_j_ = default_times_.loc[c_ids_, j_]\n",
    "            \n",
    "            c_defaulted_ = tau_j_[(tau_j_ > t0_) & (tau_j_ <= t1_)]\n",
    "            for (c_idx_, tau_) in c_defaulted_.iteritems():\n",
    "                tau_ = time_offseter(tau_, time_grid_, True)\n",
    "                tau_delta_ = time_offseter(tau_ + delta_, time_grid_, True)\n",
    "                \n",
    "                hat_s_tau_ = udl_(tau_)[0][0] * np.exp(kappa_ * tau_)\n",
    "                hat_s_tau_delta_ = udl_(tau_delta_)[0][0] * np.exp(kappa_ * tau_delta_)\n",
    "            \n",
    "                loss_c_ = notional_ * fact_f_(tau_) * positions_[c_idx_][0] * (hat_s_tau_ - hat_s_tau_delta_)\n",
    "                \n",
    "                loss_c_ = np.maximum(loss_c_, 0.)\n",
    "            \n",
    "                ccp_loss_1y_[key].loc[j_, c_idx_] = loss_c_\n",
    "\n",
    "    return ccp_loss_1y_\n",
    "            \n",
    "compute_1y_ahead_loss = partial(compute_1y_ahead_loss_, fact, kappa, delta, notional, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00, 1.00]\n",
      "[0.50, 1.50]\n",
      "[1.00, 2.00]\n",
      "[1.50, 2.50]\n",
      "[2.00, 3.00]\n",
      "[2.50, 3.50]\n",
      "[3.00, 4.00]\n",
      "[3.50, 4.50]\n",
      "[4.00, 5.00]\n",
      "[4.50, 5.00]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "loss_path = './res/sim%i/loss_1y_ahead/' % (NB_SIM)\n",
    "\n",
    "if not os.path.isdir(loss_path):\n",
    "    os.makedirs(loss_path)\n",
    "    one_y_ahead_loss = compute_1y_ahead_loss(times_cva, shifted_times_cva, default_times, udlyings)\n",
    "    \n",
    "    for k, dataframe_ in one_y_ahead_loss.iteritems():\n",
    "        path = os.path.join(loss_path, 'loss_%s.csv' % k)\n",
    "        dataframe_.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def B_(fact_f_, vol_, delta_, a_, omega_, t_):\n",
    "    if a_ <= 0.5: \n",
    "        a_ = 1. - a_\n",
    "    \n",
    "    perc_ = a_ if omega_ <= 0. else (1. - a_)\n",
    "    q_ = norm.ppf(perc_)\n",
    "    \n",
    "    var_ = vol_**2 * delta_\n",
    "    exp_factor_ = np.exp(-0.5 * var_ + np.sqrt(var_) * q_)\n",
    "    \n",
    "    tmp_res_ = 1. - exp_factor_\n",
    "    mult = np.sign(omega_)\n",
    "    \n",
    "    return mult * tmp_res_ * fact_f_(t_)\n",
    "\n",
    "B = partial(B_, fact, sigma, delta, alpha)\n",
    "\n",
    "def IM_(B_f, discount_f, kappa_, nom_, omega_, udl_, t_):\n",
    "    nom_i_ = nom_ * np.fabs(omega_)\n",
    "    b_t_ = B_f(omega_, t_)\n",
    "\n",
    "    hat_S_t_ = np.exp(kappa_ * t_) * udl_(t_)[0][0]\n",
    "    \n",
    "    return nom_i_ * b_t_ * hat_S_t_ / discount_f(t_)\n",
    "\n",
    "IM = partial(IM_, B, discount, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def A_(fact_f_, vol_, delta_, a_, omega_, t_):\n",
    "    if a_ <= 0.5: \n",
    "        a_ = 1. - a_\n",
    "    \n",
    "    var_ = vol_**2 * delta_\n",
    "    \n",
    "    perc_ = a_ if omega_ <= 0. else (1. - a_)\n",
    "    q_ = norm.ppf(perc_)\n",
    "    sqrt_var_ = np.sqrt(var_)\n",
    "    var_factor_ = np.exp(sqrt_var_ * q_)\n",
    "    \n",
    "    sgn_omega_ = np.sign(omega_)    \n",
    "    es_gauss_ = - norm.pdf(norm.ppf(a_)) / (1. - a_) * sgn_omega_\n",
    "    es_factor_ = np.exp(sqrt_var_ * es_gauss_)\n",
    "    \n",
    "    diff_term_ = (var_factor_ - es_factor_) * sgn_omega_\n",
    "    \n",
    "    comm_factor_ = (1. - a_) * fact_f_(t_) * np.exp(-0.5 * var_)\n",
    "    \n",
    "    res_ = comm_factor_ * diff_term_\n",
    "    return res_\n",
    "\n",
    "A = partial(A_, fact, sigma, delta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_(fact_f_, kappa_, vol_, delta_, omega_, udl_, tau_, t_):\n",
    "    t_ = time_offseter(t_, udl_.time, True)\n",
    "    tau_ = time_offseter(tau_, udl_.time, True)\n",
    "    tau_delta_ = time_offseter(tau_ + delta_, udl_.time, True)\n",
    "    \n",
    "    assert tau_ < t_ and t_ < tau_delta_, \"t should belong to [tau, tau^delta]\"\n",
    "    \n",
    "    hat_S_t_ = np.exp(kappa_ * t_) * udl_(t_)[0][0]\n",
    "    hat_S_tau_ = np.exp(kappa_ * tau_) * udl_(tau_)[0][0]\n",
    "    \n",
    "    std_dev_ = vol_ * np.sqrt(tau_delta_ - t_)\n",
    "    y_ = np.log(hat_S_t_ / hat_S_tau_) / std_dev_\n",
    "    y_minus_ = y_ - 0.5 * std_dev_\n",
    "    y_plus_ = y_ + 0.5 * std_dev_\n",
    "    \n",
    "    sgn_omega_ = np.sign(omega_)\n",
    "    s_t_phi_ = hat_S_t_ * norm.cdf(- y_plus_ * sgn_omega_)\n",
    "    s_tau_phi_ = hat_S_tau_ * norm.cdf(- y_minus_ * sgn_omega_)\n",
    "    \n",
    "    res_ = fact_f_(tau_) * (s_tau_phi_ - s_t_phi_) * sgn_omega_\n",
    "    \n",
    "    return res_\n",
    "\n",
    "E = partial(E_, fact, kappa, sigma, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from scipy.integrate import quad\n",
    "from scipy.integrate import simps\n",
    "\n",
    "def CVA_(A_f_, E_f_, copula_, discount_f, kappa_, delta_, nom_, swap_, c_id_, c_pos_, c_tau_, t_):\n",
    "    udl_ = swap_.underlying\n",
    "    t_ = time_offseter(t_, udl_.time, True)\n",
    "    hat_S_t_ = np.exp(kappa_ * t_) * udl_(t_)[0][0]\n",
    "    \n",
    "    if np.isnan(c_tau_):\n",
    "        return 0.\n",
    "    \n",
    "    c_tau_ = time_offseter(c_tau_, udl_.time, True)\n",
    "    inv_surv_proba_t_ = 1. / copula_.tot_survival_proba(t_, c_id_)\n",
    "    nom_i_ = np.fabs(c_pos_) * nom_\n",
    "    \n",
    "    if t_ < c_tau_:\n",
    "        def integrand(s_):\n",
    "            gamma_s_ = copula_.tot_gamma(s_, c_id_)\n",
    "            surv_proba_s_ = copula_.tot_survival_proba(s_, c_id_)\n",
    "            return A_f_(c_pos_, s_) * gamma_s_ * surv_proba_s_\n",
    "            \n",
    "        # Can't call directly\n",
    "        # integral_ = quad(integrand, t_, mat_)[0]\n",
    "        # because the integrand jumps at the coupon times\n",
    "        # and the intensity calibration times\n",
    "        sub_indexes_ = copula_.get_indexes_including(c_id_)\n",
    "        int_pillars_ = set(copula_.pillars[sub_indexes_].flatten())\n",
    "        swap_pillars_ = set(swap_.pillars)\n",
    "            \n",
    "        cut_times_ = list(int_pillars_ | swap_pillars_ | set([t_]))\n",
    "        cut_times_.sort()\n",
    "            \n",
    "        cut_times_ = np.array(cut_times_)\n",
    "        cut_times_ = cut_times_[t_ <= cut_times_]\n",
    "\n",
    "        integral_ = 0.\n",
    "        for t_i_, t_ip1_ in zip(cut_times_[:-1], cut_times_[1:]):\n",
    "            #integral_ += quad(integrand, t_i_, t_ip1_)[0]\n",
    "            x__ = np.linspace(t_i_, t_ip1_, 10)\n",
    "            y__ = [integrand(x_i_) for x_i_ in x__]\n",
    "            tmp_int__ = simps(y__, x__)\n",
    "            integral_ += tmp_int__\n",
    "\n",
    "        return nom_i_ * hat_S_t_ * inv_surv_proba_t_ * integral_ / discount_f(t_)\n",
    "        \n",
    "    c_tau_delta_ = time_offseter(c_tau_ + delta_, udl_.time, True)\n",
    "    if c_tau_ < t and t < c_tau_delta_:\n",
    "        return nom_i_ * E_f_(c_pos_, udl_, tau_i_, t_) / discount_f(t_)\n",
    "    \n",
    "CVA = partial(CVA_, A, E, copula, discount, kappa, delta, notional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 220 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit CVA(swap, 17, 4.6, 3.2, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cva(swap_, times_cva_, default_times_, udls_, all_positions_):\n",
    "    ccp_cva = dict()\n",
    "    \n",
    "    N_ = len(udls_)\n",
    "    \n",
    "    c_ids_ = default_times_.index.values\n",
    "    \n",
    "    for t_ in times_cva_:\n",
    "        key = \"%.2f\" % t_\n",
    "        print key\n",
    "        ccp_cva[key] = pd.DataFrame(0., index=range(N_), columns=c_ids_)\n",
    "        \n",
    "        for j_ in xrange(N_):\n",
    "            udl_ = udls_[j_]\n",
    "            swap_.underlying = udl_\n",
    "            \n",
    "            for c_id_ in c_ids_:\n",
    "                c_pos_ = all_positions_[c_id_][0]\n",
    "                c_tau_ = default_times_.loc[c_id_, j_]\n",
    "                ccp_cva[key].loc[j_, c_id_] = CVA(swap_, c_id_, c_pos_, c_tau_, t_)\n",
    "                \n",
    "    return ccp_cva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\n",
      "0.50\n",
      "1.00\n",
      "1.50\n",
      "2.00\n",
      "2.50\n",
      "3.00\n",
      "3.50\n",
      "4.00\n",
      "4.50\n"
     ]
    }
   ],
   "source": [
    "cva_path = './res/sim%i/cva_ccp/' % (NB_SIM)\n",
    "\n",
    "if not os.path.isdir(cva_path):\n",
    "    os.makedirs(cva_path)\n",
    "    cva_ccp = compute_cva(swap, times_cva, default_times, udlyings, positions)\n",
    "    \n",
    "    for k, dataframe_ in cva_ccp.iteritems():\n",
    "        path = os.path.join(cva_path, 'cva_%s.csv' % k)\n",
    "        dataframe_.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
