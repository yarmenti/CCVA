{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_SIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_dict_print(a_dict, level=1):\n",
    "    keys = a_dict.keys()\n",
    "    keys.sort()\n",
    "    for k in keys:\n",
    "        if type(a_dict[k]) is dict:\n",
    "            print \"\".join([\"-\" for i in range(level)]) + k\n",
    "            rec_dict_print(a_dict[k], level + 2)\n",
    "        else:\n",
    "            print \"\".join([\"-\" for i in range(level)]) + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dill\n",
    "\n",
    "loaded_data = None\n",
    "\n",
    "with open('precomputed_sims/data%i.pkl' % (NB_SIM), 'rb') as f:\n",
    "    loaded_data = dill.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec_dict_print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = loaded_data[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instead of taking 365 standard days or 252 trading days\n",
    "# in order to get some easy computations for the eqty and df time grids\n",
    "# I chose to take 360 days of tradings\n",
    "\n",
    "step = 1 / 360.\n",
    "delta = 5 * step\n",
    "\n",
    "maturity = loaded_data[\"randomization\"][\"maturity\"]\n",
    "\n",
    "print \"Maturity = %s years\" % maturity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from finance.discountfactor import ConstantRateDiscountFactor \n",
    "\n",
    "r = 0.02\n",
    "discount = ConstantRateDiscountFactor(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udlyings = loaded_data[\"underlyings\"]\n",
    "\n",
    "print \"Maximum number of paths: %i\" % len(udlyings)\n",
    "\n",
    "gbm0 = udlyings[0]\n",
    "\n",
    "kappa = gbm0.drifts[0][0]\n",
    "sigma = gbm0.vols[0][0]\n",
    "print \"kappa = %s, sigma = %s\" % (kappa, sigma)\n",
    "\n",
    "time_grid = gbm0.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derivatives_nb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from finance.products.european.swap import (\n",
    "    SwapContract,\n",
    ")\n",
    "\n",
    "swap_delta = 0.25\n",
    "\n",
    "swap_dates = SwapContract.generate_payment_dates(0, maturity, swap_delta)\n",
    "swap = SwapContract(gbm0, discount, swap_dates)\n",
    "\n",
    "price_0 = swap.price(0., incl_next_coupon=True)\n",
    "\n",
    "print swap\n",
    "print \"\\nPrice swap at t=0 without 1st coupon = %s\" % price_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p_fixed = 1.\n",
    "strike = swap.strike\n",
    "\n",
    "delta_times = swap.delta_time\n",
    "discount_factors = [discount(t) for t in swap.pillars[1:]]\n",
    "\n",
    "delta_beta_sum = np.dot(delta_times, discount_factors)\n",
    "\n",
    "notional = p_fixed / (strike*delta_beta_sum)\n",
    "\n",
    "print \"Notional on the swap: %s\" % notional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copula = loaded_data[\"credit\"][\"copula\"]\n",
    "\n",
    "c_subsets_indexes = loaded_data[\"credit\"][\"bc_subsets_indexes\"]\n",
    "\n",
    "obligors_nb = len(copula.subsets[c_subsets_indexes[-1]][0])\n",
    "print \"Obligor numbers: %s\" % obligors_nb\n",
    "\n",
    "c_ids = [17, 9, 29, 26, 50, 4, 5, 13, 64]\n",
    "c_positions = [0.69, -0.46, -0.44, -0.36, 0.34, 0.23, 0.09, -0.05, -0.04]\n",
    "\n",
    "print \"Counterparties id: %s (nb = %s)\" % (c_ids, len(c_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = np.zeros(obligors_nb)\n",
    "for idx, ps in zip(c_ids, c_positions):\n",
    "    positions[idx] = ps\n",
    "\n",
    "positions = positions / -positions[13]\n",
    "positions = np.array(positions).reshape(positions.size, 1)\n",
    "\n",
    "print positions.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_times_mat = loaded_data[\"credit\"][\"default_times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_default_times_sim(c_ids_, N_, default_times_mat_, copula_, subsets_indexes_):\n",
    "    matrix_def_ = np.zeros((len(c_ids_), N_))\n",
    "    \n",
    "    for j_, c_id_ in enumerate(c_ids_):\n",
    "        cp_subsets_indexes_ = copula_.get_indexes_including(c_id_)\n",
    "        c_df_times_indexes_ = [ii_ for ii_, ind_ in enumerate(subsets_indexes_) if ind_ in cp_subsets_indexes_]\n",
    "        \n",
    "        c_df_times_mat_ = default_times_mat_[:, c_df_times_indexes_]\n",
    "        c_df_times_ = c_df_times_mat_.min(axis=1)\n",
    "        \n",
    "        matrix_def_[j] = c_df_times_\n",
    "        \n",
    "    matrix_def_[matrix_def_==1000.] = np.nan\n",
    "        \n",
    "    df_default_times_ = pd.DataFrame(matrix_def_, index=np.array(c_ids_))\n",
    "    return df_default_times_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_times = get_default_times_sim(c_ids, N, default_times_mat, copula, c_subsets_indexes)\n",
    "default_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio P&L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for:\n",
    "\n",
    "\\begin{equation*}\n",
    "% \\sum_{t < \\tau_i^{\\delta} \\leq t+1} \n",
    "\\left( \n",
    "\\beta_{\\tau_i^{\\delta}} \\left( MtM_{\\tau_i^\\delta}^i + \\Delta^i_{\\tau_i^\\delta} \\right)\n",
    "-\\beta_{\\tau_i} \\left( {\\rm VM}_{\\tau_i}^i + {\\rm IM}_{\\tau_i}^i \\right)\n",
    "\\right)^+ \\, \\forall i\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import time_offseter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times_cva = np.arange(0, maturity, 0.5)\n",
    "\n",
    "shifted_times_cva = times_cva + 1.\n",
    "shifted_times_cva[-1] = maturity\n",
    "\n",
    "default_times.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def fact_(swap_, discount_, kappa_, delta_, t_):\n",
    "    time_grid_ = swap_.underlying.time\n",
    "    t_delta_ = time_offseter(t_ + delta_, time_grid_, True)\n",
    "    \n",
    "    coupon_dates_ = swap_.pillars\n",
    "    l_t_delta_ = np.searchsorted(coupon_dates_, t_delta_, side='left')\n",
    "\n",
    "    beta_T_l_ = map(discount_, coupon_dates_[l_t_delta_ + 1 :])    \n",
    "    h_l_ = swap_.delta_time[l_t_delta_ : ]\n",
    "    \n",
    "    T_l_m1_ = kappa_ * coupon_dates_[l_t_delta_ : -1]\n",
    "    exp_factor_ = map(np.exp, T_l_m1_)\n",
    "    \n",
    "    tmp_ = np.multiply(exp_factor_, h_l_)    \n",
    "    res_ = np.dot(beta_T_l_, tmp_)\n",
    "    \n",
    "    return res_\n",
    "\n",
    "fact = partial(fact_, swap, discount, kappa, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_1y_ahead_loss_(fact_f_, kappa_, delta_, notional_, positions_, times_cva_, shifted_times_cva_, default_times_, udls_):\n",
    "    ccp_loss_1y_ = dict()\n",
    "    \n",
    "    N_ = len(udls_)\n",
    "    \n",
    "    c_ids_ = default_times_.index.values\n",
    "    \n",
    "    for t0_, t1_ in zip(times_cva_, shifted_times_cva_):\n",
    "        key_ = \"[%.2f, %.2f]\" % (t0_, t1_)\n",
    "        print key_\n",
    "        ccp_loss_1y_[key_] = pd.DataFrame(0., index=range(N_), columns=c_ids_)\n",
    "        \n",
    "        for j_ in xrange(N_):\n",
    "            udl_ = udls_[j_]\n",
    "            time_grid_ = udl_.time\n",
    "            tau_j_ = default_times_.loc[c_ids_, j_]\n",
    "            \n",
    "            c_defaulted_ = tau_j_[(tau_j_ > t0_) & (tau_j_ <= t1_)]\n",
    "            for (c_idx_, tau_) in c_defaulted_.iteritems():\n",
    "                tau_ = time_offseter(tau_, time_grid_, True)\n",
    "                tau_delta_ = time_offseter(tau_ + delta_, time_grid_, True)\n",
    "                \n",
    "                hat_s_tau_ = udl_(tau_)[0][0] * np.exp(kappa_ * tau_)\n",
    "                hat_s_tau_delta_ = udl_(tau_delta_)[0][0] * np.exp(kappa_ * tau_delta_)\n",
    "            \n",
    "                loss_c_ = notional_ * fact_f_(tau_) * positions_[c_idx_][0] * (hat_s_tau_ - hat_s_tau_delta_)\n",
    "                \n",
    "                ccp_loss_1y_[key].loc[j_, c_idx_] = np.maximum(loss_c_, 0.)\n",
    "\n",
    "    return ccp_loss_1y_\n",
    "            \n",
    "compute_1y_ahead_loss = partial(compute_1y_ahead_loss_, fact, kappa, delta, notional, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "loss_path = './res/sim%i/loss_1y_ahead/' % (NB_SIM)\n",
    "\n",
    "if not os.path.isdir(loss_path):\n",
    "    os.makedirs(loss_path)\n",
    "    one_y_ahead_loss = compute_1y_ahead_loss(times_cva, shifted_times_cva, default_times, udlyings)\n",
    "    \n",
    "    for k, dataframe_ in one_y_ahead_loss.iteritems():\n",
    "        path = os.path.join(loss_path, 'loss_%s.csv' % k)\n",
    "        dataframe_.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def B_(fact_f_, vol_, delta_, a_, omega_, t_):\n",
    "    if a_ <= 0.5: \n",
    "        a_ = 1. - a_\n",
    "    \n",
    "    perc_ = a_ if omega_ <= 0. else (1. - a_)\n",
    "    q_ = norm.ppf(perc_)\n",
    "    \n",
    "    var_ = vol_**2 * delta_\n",
    "    exp_factor_ = np.exp(-0.5 * var_ + np.sqrt(var_) * q_)\n",
    "    \n",
    "    tmp_res_ = 1. - exp_factor_\n",
    "    \n",
    "    return np.sign(omega_) * tmp_res_ * fact_f_(t_)\n",
    "\n",
    "B = partial(B_, fact, sigma, delta, alpha)\n",
    "\n",
    "def IM_(B_f, discount_f, kappa_, nom_, omega_, udl_, t_):\n",
    "    nom_i_ = nom_ * np.fabs(omega_)\n",
    "    b_t_ = B_f(omega_, t_)\n",
    "\n",
    "    hat_S_t_ = np.exp(kappa_ * t_) * udl_(t_)[0][0]\n",
    "    \n",
    "    return nom_i_ * b_t_ * hat_S_t_ / discount_f(t_)\n",
    "\n",
    "IM = partial(IM_, B, discount, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def A_(fact_f_, vol_, delta_, a_, omega_, t_):\n",
    "    if a_ <= 0.5: \n",
    "        a_ = 1. - a_\n",
    "    \n",
    "    var_ = vol_**2 * delta_\n",
    "    \n",
    "    perc_ = a_ if omega_ <= 0. else (1. - a_)\n",
    "    q_ = norm.ppf(perc_)\n",
    "    sqrt_var_ = np.sqrt(var_)\n",
    "    var_factor_ = np.exp(sqrt_var_ * q_)\n",
    "    \n",
    "    sgn_omega_ = np.sign(omega_)\n",
    "    es_gauss_ = - norm.pdf(norm.ppf(a_)) / (1. - a_) * sgn_omega_\n",
    "    es_factor_ = np.exp(sqrt_var_ * es_gauss_)\n",
    "    \n",
    "    diff_term_ = (var_factor_ - es_factor_) * sgn_omega_\n",
    "    \n",
    "    comm_factor_ = (1. - a_) * fact_f_(t_) * np.exp(-0.5 * var_)\n",
    "    \n",
    "    res_ = comm_factor_ * diff_term_\n",
    "    return res_\n",
    "\n",
    "A = partial(A_, fact, sigma, delta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_(fact_f_, kappa_, vol_, delta_, omega_, udl_, tau_, t_):\n",
    "    t_ = time_offseter(t_, udl_.time, True)\n",
    "    tau_ = time_offseter(tau_, udl_.time, True)\n",
    "    tau_delta_ = time_offseter(tau_ + delta_, udl_.time, True)\n",
    "    \n",
    "    assert tau_ < t_ and t_ < tau_delta_, \"t should belong to [tau, tau^delta]\"\n",
    "    \n",
    "    hat_S_t_ = np.exp(kappa_ * t_) * udl_(t_)[0][0]\n",
    "    hat_S_tau_ = np.exp(kappa_ * tau_) * udl_(tau_)[0][0]\n",
    "    \n",
    "    std_dev_ = vol_ * np.sqrt(tau_delta_ - t_)\n",
    "    y_ = np.log(hat_S_t_ / hat_S_tau_) / std_dev_\n",
    "    y_minus_ = y_ - 0.5 * std_dev_\n",
    "    y_plus_ = y_ + 0.5 * std_dev_\n",
    "    \n",
    "    sgn_omega_ = np.sign(omega_)\n",
    "    s_t_phi_ = hat_S_t_ * norm.cdf(- y_plus_ * sgn_omega_)\n",
    "    s_tau_phi_ = hat_S_tau_ * norm.cdf(- y_minus_ * sgn_omega_)\n",
    "    \n",
    "    res_ = fact_f_(tau_) * (s_tau_phi_ - s_t_phi_) * sgn_omega_\n",
    "    \n",
    "    return res_\n",
    "\n",
    "E = partial(E_, fact, kappa, sigma, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from scipy.integrate import quad\n",
    "from scipy.integrate import simps\n",
    "\n",
    "def CVA_(A_f_, E_f_, copula_, discount_f_, kappa_, delta_, nom_, swap_, c_id_, c_pos_, c_tau_, t_):\n",
    "    udl_ = swap_.underlying\n",
    "    t_ = time_offseter(t_, udl_.time, True)\n",
    "    hat_S_t_ = udl_(t_)[0][0] * np.exp(kappa_ * t_)\n",
    "    \n",
    "    if np.isnan(c_tau_):\n",
    "        return 0.\n",
    "    \n",
    "    c_tau_ = time_offseter(c_tau_, udl_.time, True)\n",
    "    inv_surv_proba_t_ = 1. / copula_.tot_survival_proba(t_, c_id_)\n",
    "    nom_i_ = np.fabs(c_pos_) * nom_\n",
    "    \n",
    "    if t_ < c_tau_:\n",
    "        def integrand(s_):\n",
    "            gamma_s_ = copula_.tot_gamma(s_, c_id_)\n",
    "            surv_proba_s_ = copula_.tot_survival_proba(s_, c_id_)\n",
    "            return A_f_(c_pos_, s_) * gamma_s_ * surv_proba_s_\n",
    "            \n",
    "        # Can't call directly\n",
    "        # integral_ = quad(integrand, t_, mat_)[0]\n",
    "        # because the integrand jumps at the coupon times\n",
    "        # and the intensity calibration times\n",
    "        sub_indexes_ = copula_.get_indexes_including(c_id_)\n",
    "        int_pillars_ = set(copula_.pillars[sub_indexes_].flatten())\n",
    "        swap_pillars_ = set(swap_.pillars)\n",
    "            \n",
    "        cut_times_ = list(int_pillars_ | swap_pillars_ | set([t_]))\n",
    "        cut_times_.sort()\n",
    "            \n",
    "        cut_times_ = np.array(cut_times_)\n",
    "        cut_times_ = cut_times_[t_ <= cut_times_]\n",
    "\n",
    "        integral_ = 0.\n",
    "        for t_i_, t_ip1_ in zip(cut_times_[:-1], cut_times_[1:]):\n",
    "            #integral_ += quad(integrand, t_i_, t_ip1_)[0]\n",
    "            x__ = np.linspace(t_i_, t_ip1_, 10)\n",
    "            y__ = [integrand(x_i_) for x_i_ in x__]\n",
    "            tmp_int__ = simps(y__, x__)\n",
    "            integral_ += tmp_int__\n",
    "\n",
    "        return nom_i_ * hat_S_t_ * inv_surv_proba_t_ * integral_ / discount_f_(t_)\n",
    "        \n",
    "    c_tau_delta_ = time_offseter(c_tau_ + delta_, udl_.time, True)\n",
    "    if c_tau_ < t_ and t_ < c_tau_delta_:\n",
    "        return nom_i_ * E_f_(c_pos_, udl_, c_tau_, t_) / discount_f_(t_)\n",
    "    \n",
    "    return 0.\n",
    "    \n",
    "CVA = partial(CVA_, A, E, copula, discount, kappa, delta, notional)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#%timeit CVA(swap, 17, 4.6, 3.2, 0.)\n",
    "#%timeit CVA(swap, 17, 4.6, 3.2 - 0.5*delta, 3.2)\n",
    "\n",
    "print CVA(swap, 17, 4.6, 3.2, 0.)\n",
    "print CVA(swap, 17, -4.6, 3.2 - 0.2*delta, 3.2)\n",
    "print CVA(swap, 17, -4.6, 1.5, 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cva(swap_, times_cva_, default_times_, udls_, all_positions_):\n",
    "    ccp_cva = dict()\n",
    "    \n",
    "    N_ = len(udls_)\n",
    "    \n",
    "    c_ids_ = default_times_.index.values\n",
    "    \n",
    "    for t_ in times_cva_:\n",
    "        key = \"%.2f\" % t_\n",
    "        print key\n",
    "        ccp_cva[key] = pd.DataFrame(0., index=range(N_), columns=c_ids_)\n",
    "        \n",
    "        for j_ in xrange(N_):\n",
    "            udl_ = udls_[j_]\n",
    "            swap_.underlying = udl_\n",
    "            \n",
    "            for c_id_ in c_ids_:\n",
    "                c_pos_ = all_positions_[c_id_][0]\n",
    "                c_tau_ = default_times_.loc[c_id_, j_]\n",
    "                cva_c_id = CVA(swap_, c_id_, c_pos_, c_tau_, t_)\n",
    "                \n",
    "                if not isinstance(cva_c_id, float):\n",
    "                    raise Exception(\"cva computation failed\")\n",
    "                \n",
    "                ccp_cva[key].loc[j_, c_id_] = CVA(swap_, c_id_, c_pos_, c_tau_, t_)\n",
    "                \n",
    "    return ccp_cva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cva_path = './res/sim%i/cva_ccp/' % (NB_SIM)\n",
    "\n",
    "if not os.path.isdir(cva_path):\n",
    "    os.makedirs(cva_path)\n",
    "    cva_ccp = compute_cva(swap, times_cva, default_times, udlyings, positions)\n",
    "    \n",
    "    for k, dataframe_ in cva_ccp.iteritems():\n",
    "        path = os.path.join(cva_path, 'cva_%s.csv' % k)\n",
    "        dataframe_.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
